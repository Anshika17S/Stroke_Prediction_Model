# ğŸ§  Stroke Prediction using Machine Learning Pipeline

This project uses a Decision Tree Classifier to predict the likelihood of a stroke based on medical and demographic features. The model is built using a complete preprocessing and modeling pipeline in scikit-learn, including imputation, encoding, feature selection, and classification.

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ StrokePrediction_WithPipelines.ipynb          # Main ML pipeline notebook
â”œâ”€â”€ Prediction_Using_Pipeline.ipynb               # Prediction logic using trained pipeline
â”œâ”€â”€ healthcare-dataset-stroke-data.csv            # Dataset (from Kaggle)
â”œâ”€â”€ pipe.pkl                                      # Saved model pipeline 
â”œâ”€â”€ requirements.txt                              # List of Python packages required
â””â”€â”€ README.md                                     # Project documentation


---

## ğŸ“Š Dataset

- **Source:** [Kaggle - Stroke Prediction Dataset](https://www.kaggle.com/fedesoriano/stroke-prediction-dataset)
- **Features:**
  - `gender`, `age`, `hypertension`, `heart_disease`, `ever_married`, `work_type`, `Residence_type`, `avg_glucose_level`, `bmi`, `smoking_status`
- **Target:**
  - `stroke` (1: patient had a stroke, 0: did not)

---

## ğŸ› ï¸ Preprocessing Steps

- **Imputation:** Missing values in `bmi` handled using `SimpleImputer (median)`
- **Encoding:**
  - `OneHotEncoder`: for categorical features like gender, work_type, smoking_status
  - `OrdinalEncoder`: for binary features like ever_married, Residence_type
- **Feature Selection:** `SelectKBest` using Chi-squared test
- **Model:** `DecisionTreeClassifier`
- **Pipeline:** Entire workflow wrapped using `ColumnTransformer` and `Pipeline` from scikit-learn

---

## ğŸš€ How to Run

1. **Clone the repository**  
```bash
   git clone https://github.com/Anshika17S/Stroke_Prediction_Model.git
   cd Stroke_Prediction_Model
   ```

2. **Install dependencies**
    (Make sure Python is installed, and use a virtual environment if needed)
```bash
pip install -r requirements.txt
```

3. **Run the notebooks**

- ğŸ“˜ `StrokePrediction_WithPipelines.ipynb`  
  This is the main notebook where the pipeline is built, trained, and evaluated using the dataset.

- ğŸ” `Prediction_Using_Pipeline.ipynb`  
  This notebook loads the saved pipeline (`pipe.pkl`) using `pickle` and makes predictions on new data.

  > âš™ï¸ This project requires **Python 3.8+** and works well with **Jupyter Notebook** or **VS Code** (with Jupyter extension).


  ## ğŸ‘©â€ğŸ’» Author

**Anshika Sharma**

- [GitHub](https://github.com/Anshika17S)
- [LinkedIn](https://www.linkedin.com/in/anshika-sharma-135a47316/)
- [Kaggle](https://www.kaggle.com/anshika17s)

## ğŸ“ License

This project is licensed under the [MIT License](LICENSE).
